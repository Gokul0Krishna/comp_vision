{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1e3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94400b6",
   "metadata": {},
   "source": [
    "loading up the paths to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d3668e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=[]\n",
    "trainy=[]\n",
    "i=0\n",
    "for image in os.listdir(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Train\\WithoutMask\"):\n",
    "    image_path = os.path.join(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Train\\WithoutMask\", image)\n",
    "    i=i+1\n",
    "    trainx.append(image_path)\n",
    "    trainy.append(0)\n",
    "    if i==250:\n",
    "        break\n",
    "i=0\n",
    "for image in os.listdir(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Train\\WithMask\"):\n",
    "    image_path = os.path.join(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Train\\WithMask\", image)\n",
    "    i=i+1\n",
    "    trainx.append(image_path)\n",
    "    trainy.append(1)\n",
    "    if i==250:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9f5330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff821f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "testx=[]\n",
    "testy=[]\n",
    "i=0\n",
    "for image in os.listdir(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Test\\WithoutMask\"):\n",
    "    image_path = os.path.join(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Test\\WithoutMask\", image)\n",
    "    i=i+1\n",
    "    testx.append(image_path)\n",
    "    testy.append(0)\n",
    "    if i==50:\n",
    "        break\n",
    "i=0\n",
    "for image in os.listdir(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Test\\WithMask\"):\n",
    "    image_path = os.path.join(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Test\\WithMask\", image)\n",
    "    i=i+1\n",
    "    testx.append(image_path)\n",
    "    testy.append(1)\n",
    "    if i==50:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d54852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2d490c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valx=[]\n",
    "valy=[]\n",
    "i=0\n",
    "for image in os.listdir(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Validation\\WithoutMask\"):\n",
    "    image_path = os.path.join(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Validation\\WithoutMask\", image)\n",
    "    i=i+1\n",
    "    valx.append(image_path)\n",
    "    valy.append(0)\n",
    "    if i==50:\n",
    "        break\n",
    "i=0\n",
    "for image in os.listdir(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Validation\\WithMask\"):\n",
    "    image_path = os.path.join(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\Face Mask Dataset\\Validation\\WithMask\", image)\n",
    "    i=i+1\n",
    "    valx.append(image_path)\n",
    "    valy.append(1)\n",
    "    if i==50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3ed3a5",
   "metadata": {},
   "source": [
    "storing the images as reshaped arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aeca930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trianimgx=[]\n",
    "for  i in trainx:\n",
    "    image = Image.open(i)\n",
    "    resized_image = image.resize((224, 224))\n",
    "    image_array = np.array(resized_image)\n",
    "    normalized_image = image_array / 255.0\n",
    "    # batch_image = np.expand_dims(normalized_image, axis=0) only if needed\n",
    "    trianimgx.append(normalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bddc9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimgx=[]\n",
    "for  i in testx:\n",
    "    image = Image.open(i)\n",
    "    resized_image = image.resize((224, 224))\n",
    "    image_array = np.array(resized_image)\n",
    "    normalized_image = image_array / 255.0\n",
    "    # batch_image = np.expand_dims(normalized_image, axis=0) only if needed\n",
    "    testimgx.append(normalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27905c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valimgx=[]\n",
    "for  i in valx:\n",
    "    image = Image.open(i)\n",
    "    resized_image = image.resize((224, 224))\n",
    "    image_array = np.array(resized_image)\n",
    "    normalized_image = image_array / 255.0\n",
    "    # batch_image = np.expand_dims(normalized_image, axis=0) only if needed\n",
    "    valimgx.append(normalized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dd1d3d",
   "metadata": {},
   "source": [
    "storing the data in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82408a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=pd.DataFrame({\"X\":trianimgx,\"Y\":trainy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf=pd.DataFrame({\"X\":testimgx,\"Y\":testy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61c44074",
   "metadata": {},
   "outputs": [],
   "source": [
    "valdf=pd.DataFrame({\"X\":valimgx,\"Y\":valy})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1b2b8",
   "metadata": {},
   "source": [
    "shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5a6bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf_final=traindf.sample(frac=1, random_state=42)\n",
    "testdf_final=testdf.sample(frac=1,random_state=42)\n",
    "valdf_final=valdf.sample(frac=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
